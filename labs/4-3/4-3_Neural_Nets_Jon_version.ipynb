{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LEGALST-190] Lab 4/3: Neural Nets\n",
    "\n",
    "In this lab, we'll learn how to implement neural net methods to pattern recognize handwriting images.\n",
    "\n",
    "\n",
    "*Estimated Time: 30-40 minutes*\n",
    "\n",
    "---\n",
    "### Table of Contents\n",
    "\n",
    "[The Data](#section data)<br>\n",
    "\n",
    "1 - [Visualizing Data](#section 1)<br>\n",
    "\n",
    "2 - [Neural Network](#section 2)<br>\n",
    "\n",
    "3 - [Multi-Layer Perceptrons](#section 3)<br>\n",
    "\n",
    "4 - [A Simple MLP](#section 4)<br>\n",
    "\n",
    "5 - [Convolutional Nerual Networks](#section 5)<br>\n",
    "\n",
    "**Dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /srv/app/venv/lib/python3.6/site-packages\n",
      "Requirement already satisfied: keras in /srv/app/venv/lib/python3.6/site-packages\n",
      "Requirement already satisfied: wheel>=0.26 in /srv/app/venv/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /srv/app/venv/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: tensorflow-tensorboard<0.2.0,>=0.1.0 in /srv/app/venv/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: protobuf>=3.3.0 in /srv/app/venv/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: six>=1.10.0 in /srv/app/venv/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: scipy>=0.14 in /srv/app/venv/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: pyyaml in /srv/app/venv/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /srv/app/venv/lib/python3.6/site-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow)\n",
      "Requirement already satisfied: html5lib==0.9999999 in /srv/app/venv/lib/python3.6/site-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /srv/app/venv/lib/python3.6/site-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow)\n",
      "Requirement already satisfied: bleach==1.5.0 in /srv/app/venv/lib/python3.6/site-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow)\n",
      "Requirement already satisfied: setuptools in /srv/app/venv/lib/python3.6/site-packages (from protobuf>=3.3.0->tensorflow)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Data <a id='data'></a>\n",
    "\n",
    "In this notebook, you'll be working with the MNIST handwriting dataset, considered \"hello, world\" of object recognition in machine learning. It contains images of handwritten digits centered and normalized. Modified NIST (National Institute of Standards and Technology) is constructed from scanned documents available from NIST. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Data  <a id='section 1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras deep learning library provides a convenience method for loading the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the dataset is split into a set to train our model and one to test it. X_train and X_test are inputs while y_train and y_test are outputs.\n",
    "\n",
    "Let's visualize MNIST dataset by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdef7074400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network <a id='section 2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are a set of algorithms, modeled loosely after the human brain, that are designed to recognize patterns.\n",
    "\n",
    "Neural networks help us cluster and classify. They group unlabeled data according to similarities among the example inputs.\n",
    "\n",
    "Classification problems depend on labeled datasets, i.e. humans need to label the data for a neural to learn the correlation between labels and data. This is <i>supervised learning</i>. Below, we'll dive into MLP, which utilizes a supervised learning technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptrons <a id='section 3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multi-layer perceptron (MLP) is a class of neural network that consists of at least three layers of nodes (first layer being inputs and last layer being outputs). Except for the input layer, activation of nodes of a certain layer depends on which nodes are activated in the previous layer. Each node is a neuron that uses a nonlinear activation function. Below is an image that represents a MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"https://www.safaribooksonline.com/library/view/getting-started-with/9781786468574/graphics/B05474_04_05.jpg\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multilayer perceptron (MLP) is a deep, artificial neural network. They are composed of an input layer to receive the signal, an output layer that makes a decision or prediction about the input, and in between those two, an arbitrary number of hidden layers that are the true computational engine of the MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPs train on a set of input-output pairs and learn to model the correlation between those inputs and outputs by adjusting parameters to minimize error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple MLP <a id='section 4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to build a simple MLP to identify digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input vs. Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Each pixel of an image will be an input to our MLP.\n",
    "\n",
    "<b>Question:</b> How many nodes would our MLP's first layer have for a 20x20 image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'm not exactly sure which layer is the first, but since there are 400 total pixels, and each one is a node, that would be 400."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output layer will produce what we are looking for.\n",
    "\n",
    "<b>Question:</b> What will each node in the output layer represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each node should represent a character 0-9, right? the output layer is the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset is a 3-D array of instance, image width, image height. To make an image \"inputable\" to our MLP, we need to vectorize the representations of MNIST training dataset, i.e. we need to flatten a image into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "num_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy's reshape function can help flatten multi-dimensional arrays\n",
    "# As all images are 28x28 pixels, we flatten all into vectors of length 784\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
       "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
       "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
       "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
       "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
       "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
       "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
       "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel values are grey scale, which ranges from 0-255. Neural network models work better with normalized inputs. Thus, normalize our training dataset below so that values range from 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.01176471,  0.07058824,  0.07058824,\n",
       "        0.07058824,  0.49411765,  0.53333333,  0.68627451,  0.10196078,\n",
       "        0.65098039,  1.        ,  0.96862745,  0.49803922,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.11764706,  0.14117647,  0.36862745,  0.60392157,\n",
       "        0.66666667,  0.99215686,  0.99215686,  0.99215686,  0.99215686,\n",
       "        0.99215686,  0.88235294,  0.6745098 ,  0.99215686,  0.94901961,\n",
       "        0.76470588,  0.25098039,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.19215686,  0.93333333,\n",
       "        0.99215686,  0.99215686,  0.99215686,  0.99215686,  0.99215686,\n",
       "        0.99215686,  0.99215686,  0.99215686,  0.98431373,  0.36470588,\n",
       "        0.32156863,  0.32156863,  0.21960784,  0.15294118,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.07058824,  0.85882353,  0.99215686,  0.99215686,\n",
       "        0.99215686,  0.99215686,  0.99215686,  0.77647059,  0.71372549,\n",
       "        0.96862745,  0.94509804,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.31372549,  0.61176471,  0.41960784,  0.99215686,  0.99215686,\n",
       "        0.80392157,  0.04313725,  0.        ,  0.16862745,  0.60392157,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.05490196,\n",
       "        0.00392157,  0.60392157,  0.99215686,  0.35294118,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.54509804,\n",
       "        0.99215686,  0.74509804,  0.00784314,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.04313725,  0.74509804,  0.99215686,\n",
       "        0.2745098 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.1372549 ,  0.94509804,  0.88235294,  0.62745098,\n",
       "        0.42352941,  0.00392157,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.31764706,  0.94117647,  0.99215686,  0.99215686,  0.46666667,\n",
       "        0.09803922,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.17647059,\n",
       "        0.72941176,  0.99215686,  0.99215686,  0.58823529,  0.10588235,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.0627451 ,  0.36470588,\n",
       "        0.98823529,  0.99215686,  0.73333333,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.97647059,  0.99215686,\n",
       "        0.97647059,  0.25098039,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.18039216,  0.50980392,\n",
       "        0.71764706,  0.99215686,  0.99215686,  0.81176471,  0.00784314,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.15294118,\n",
       "        0.58039216,  0.89803922,  0.99215686,  0.99215686,  0.99215686,\n",
       "        0.98039216,  0.71372549,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.09411765,  0.44705882,  0.86666667,  0.99215686,  0.99215686,\n",
       "        0.99215686,  0.99215686,  0.78823529,  0.30588235,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.09019608,  0.25882353,  0.83529412,  0.99215686,\n",
       "        0.99215686,  0.99215686,  0.99215686,  0.77647059,  0.31764706,\n",
       "        0.00784314,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.07058824,  0.67058824,  0.85882353,\n",
       "        0.99215686,  0.99215686,  0.99215686,  0.99215686,  0.76470588,\n",
       "        0.31372549,  0.03529412,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.21568627,  0.6745098 ,\n",
       "        0.88627451,  0.99215686,  0.99215686,  0.99215686,  0.99215686,\n",
       "        0.95686275,  0.52156863,  0.04313725,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.53333333,  0.99215686,  0.99215686,  0.99215686,\n",
       "        0.83137255,  0.52941176,  0.51764706,  0.0627451 ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs (y_train and y_test) are integers from 0 to 9 and we can think fo each integer as a class. We'll use a one-hot encoding of the class values, which transforms the output vector into a binary matrix.\n",
    "\n",
    "<i>One-hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 7, 6, 0, 9, 7, 5, 7, 2, 1, 1, 6, 8, 9, 4, 1, 5, 2, 2, 9, 0, 3, 9,\n",
       "       6, 7, 2, 0, 3, 5, 4], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[300:330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use built-in function in np_utils\n",
    "from keras.utils import np_utils\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure that we still have 10 classes(0-9) after one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = y_test.shape[1]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras has useful methods we can utilize to develop an MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the methods we need\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empty MLP, i.e. empty linear stack of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an input layer using the Dense function (refer to <a href=\"https://keras.io/layers/core/\">this doc</a>), then add the layer to our model using `model.add(...)`. The input layer should use 'relu' activation, a 'normal' kernel_initializer, and the number of pixels for input_dim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dense(...) creates a regular densely connected layer. \n",
    "relu is a rectifier activation function.\n",
    "\"\"\"\n",
    "model.add(Dense(num_pixels, activation='relu',kernel_initializer='normal', input_dim=num_pixels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and add in the output layer to our model. Use 'softmax' activation and a normal kernel_initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A softmax activation function is used on the output layer to turn the outputs into \n",
    "probability-like values\n",
    "\"\"\"\n",
    "model.add(Dense(num_classes, activation='softmax',kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "categorical_crossentropy is a logarithmic loss function and\n",
    "adam is a gradient descent algorithm\n",
    "\"\"\"\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now fit our model on the training datasets. We fit our model over 10 epochs and update it every 200 images. It might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5s - loss: 0.2751 - acc: 0.9231 - val_loss: 0.1392 - val_acc: 0.9583\n",
      "Epoch 2/10\n",
      "5s - loss: 0.1097 - acc: 0.9689 - val_loss: 0.0973 - val_acc: 0.9710\n",
      "Epoch 3/10\n",
      "5s - loss: 0.0700 - acc: 0.9800 - val_loss: 0.0893 - val_acc: 0.9736\n",
      "Epoch 4/10\n",
      "5s - loss: 0.0503 - acc: 0.9857 - val_loss: 0.0757 - val_acc: 0.9753\n",
      "Epoch 5/10\n",
      "5s - loss: 0.0353 - acc: 0.9900 - val_loss: 0.0670 - val_acc: 0.9788\n",
      "Epoch 6/10\n",
      "7s - loss: 0.0265 - acc: 0.9928 - val_loss: 0.0615 - val_acc: 0.9794\n",
      "Epoch 7/10\n",
      "6s - loss: 0.0192 - acc: 0.9953 - val_loss: 0.0616 - val_acc: 0.9806\n",
      "Epoch 8/10\n",
      "6s - loss: 0.0139 - acc: 0.9971 - val_loss: 0.0607 - val_acc: 0.9815\n",
      "Epoch 9/10\n",
      "6s - loss: 0.0106 - acc: 0.9980 - val_loss: 0.0641 - val_acc: 0.9808\n",
      "Epoch 10/10\n",
      "6s - loss: 0.0089 - acc: 0.9984 - val_loss: 0.0638 - val_acc: 0.9812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdef4330518>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the log of our training produced above, what can you conclude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That the gains in accuracy really happen after only a couple of iterations through the data, and that the model is really quite accurate at identifying the numeral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate our model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1.88%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x7fdef705c780>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = model.get_layer(index=2)\n",
    "layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks <a id='section 5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPs did give us pretty good accuracy. However, as each pixel of an image is an input, we will have too many inputs for a large image. Convolutional neural nets, on the other hand, can take in 3-D inputs (2D + color) instead of just 1-D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How a CNN works <a id='conv_image'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.mathworks.com/content/mathworks/www/en/discovery/convolutional-neural-network/jcr:content/mainParsys/image_copy.adapt.full.high.jpg/1517522275430.jpg\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNets have \"features\" and match them with parts of an image rather than the whole thing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/match_pieces.png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, we have three features: left-to-right diagonal, central X, and right to left diagonal. To match features, we use a process called filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Assign each black pixel -1 and each white pixel 1. \n",
    "2. Line up a feature with an image patch (for example, line up left-to-right diagonal with the green box above)\n",
    "3. Multiply each feature pixel with the corresponding image patch pixel\n",
    "4. Take the average of the products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question:</b> In the example above when we match the left-to-right diagonal feature with the green box, what would the process output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### it would output the following matrix\n",
    "1 -1 -1<p>\n",
    "-1 1 -1<p>\n",
    "-1 -1 1<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Layer\n",
    " \n",
    "The process of filtering for every possible image patch with every feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/convolution.png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the image above, after applying our left-to-right diagonal filter, we get higher scores on the left to right diagonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question:</b> If we apply the central X filter in this example, where will the highest score occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right in the middle on the central x in the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU (Rectified Linear Units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is applied on filtered images. It simply changes every negative value to 0 and leaves positive values unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this layer, we shrink the filtered images by the following process:\n",
    "1. Pick a window size and a stride size\n",
    "2. Walk our window on the filtered image, each time shifting by the stride size\n",
    "3. For each step, take the maximum score contained in the window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/pooling.png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This layer helps because it does not care about where in the window the maximum value occurs, i.e. it's less sensitive to specific positioning of pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question:</b> How would the pooling layer help in classifying digits? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The pooling layer allows for somewhat differently shaped characters--slanty 5's, misshapen 3's etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully Connected Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This layer flattens the pooled images and each value gets a vote, which is how strongly that value suggests a certain outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One question you might have now is where do the initial features and voting weights come from. They are obtained by a process called <a href=\"https://brilliant.org/wiki/backpropagation/\">backpropragation</a>, explained in more detail at the link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've learned that the layers are combined together: <b>convolutional + ReLU + pooling</b> constitute the first part while <b>fully connected</b> the second. One note is that each part can be applied multiple times, as we can see in [the overview of a CNN at the beginning](#conv_image)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras also provides useful methods to create a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Keras, the layers used for two-dimensional convolutions expect pixel values with the dimensions [pixels][width][height]. We'll set the pixels dimension to 1 because the pixel values in MNIST are gray scale. As a reminder, all images in MNIST are 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, fill out the blanks to normalize the datasets and one hot encode the output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function that creates our CNN. Read through the comments to understand what each line does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # A convolutional layer that has 32 features of size 5x5\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    \n",
    "    # A pooling layer with a window size of 2x2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # A dropout layer that randomly excludes 20% of neurons in the layer \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # A flatten layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # A fully connected layer with 128 neurons\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    # An output layer with softmax as in MLP\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model as before in MLP\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_model()\n",
    "# Fit the model\n",
    "model.fit(..., ..., validation_data=(..., ...), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# Evaluation of the model\n",
    "scores = model.evaluate(..., ..., verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's experiment with the parameters: number of features, size of features, size of the window in pooling, dropout percentage, and so on. Modify the parameters to your best judgment in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_CNN_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # A convolutional layer that has 32 features of size 5x5\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    \n",
    "    # A pooling layer with a window size of 2x2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # A dropout layer that randomly excludes 20% of neurons in the layer \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # A flatten layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # A fully connected layer with 128 neurons\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    # An output layer with softmax as in MLP\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model as before in MLP\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = diff_CNN_model()\n",
    "# Fit the model\n",
    "model.fit(..., ..., validation_data=(..., ...), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# Evaluation of the model\n",
    "scores = model.evaluate(..., ..., verbose=0)\n",
    "print(\"diff_CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you get different accuracies for the two different models? Make some conclusions about different parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Your Answer Here</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image source:\n",
    "- How Convolutional Neural Networks work, https://www.youtube.com/watch?v=FmpDIaiMIeA&t=1070s\n",
    "\n",
    "Code source:\n",
    "- Handwritten Digit Recognition using Convolutional Neural Networks in Python with Keras, https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Notebook developed by: Tian Qin\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
